# -*- coding: utf-8 -*-
"""countryrecommendation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1I8OJfEAX0bB2WezFeQVzlUwv0jNo9sLO

# Country Recommendation System Based on Socioeconomic and Environmental Indicators

This project aims to develop a data-driven system that recommends countries to users based on
their preferences regarding various socioeconomic and environmental indicators. The core
objective is to predict the Quality of Life Index (QoLI) for a user-defined profile and suggest the
top five countries that are most similar to that profile. This is achieved by comparing the userâ€™s
input against the actual data of countries through a distance computation model.
"""

import requests
from bs4 import BeautifulSoup
import pandas as pd
import re
import time

"""## Data Scrapping

Data was collected from sources like Numbeo for indicators including crime rate, healthcare,
pollution, safety, and cost of living, and from Weather and Climate for average annual
temperature.
"""

url_for_crime_and_safety = "https://www.numbeo.com/crime/rankings_by_country.jsp"
url_for_cost_of_living= "https://www.numbeo.com/cost-of-living/rankings_by_country.jsp"
url_for_health="https://www.numbeo.com/health-care/rankings_by_country.jsp"
url_for_pollution= "https://www.numbeo.com/pollution/rankings_by_country.jsp"
url_for_climate="https://weatherandclimate.com/countries"
url_for_quality_of_life="https://www.numbeo.com/quality-of-life/rankings_by_country.jsp"

response = requests.get(url_for_crime_and_safety)
soup = BeautifulSoup(response.content, "html.parser")

# Storage
Country_Names,Crime_Indexes, Safety_Indexes = [], [],[]
Pollution_Indexes=[]
Healthcare_Indexes=[]
Costs_Of_Living=[]
Climate_Indexes=[]
Rents_Indexes=[]
Groceries_Indexes=[]
Quality_Indexes=[]

table=soup.tbody
rows = table.find_all("tr")

for row in rows:
    tds = row.find_all("td")
    # extract the values
    countryName=tds[1].text.strip() if len(tds)>1 else None
    crimeIndex = tds[2].text.strip() if len(tds) > 2 else None
    safetyIndex = tds[3].text.strip() if len(tds) > 3 else None

    Country_Names.append(countryName)
    Crime_Indexes.append(crimeIndex)
    Safety_Indexes.append(safetyIndex)

df1 = pd.DataFrame({
    "Country": Country_Names,
    "Crime Index": Crime_Indexes,
    "Safety Index": Safety_Indexes,
})

print(df1)

response = requests.get(url_for_pollution)
soup = BeautifulSoup(response.content, "html.parser")

Country_Names=[]
table=soup.tbody
rows = table.find_all("tr")

for row in rows:
    tds = row.find_all("td")
    # extract the values
    countryName=tds[1].text.strip() if len(tds)>1 else None
    pollutionIndex = tds[2].text.strip() if len(tds) > 2 else None

    Country_Names.append(countryName)
    Pollution_Indexes.append(pollutionIndex)

df2 = pd.DataFrame({
    "Country": Country_Names,
    "Pollution Index": Pollution_Indexes,
})

print(df2)

response = requests.get(url_for_quality_of_life)
soup = BeautifulSoup(response.content, "html.parser")

Country_Names=[]
table=soup.tbody
rows = table.find_all("tr")

for row in rows:
    tds = row.find_all("td")
    # extract the values
    countryName=tds[1].text.strip() if len(tds)>1 else None
    qualities = tds[2].text.strip() if len(tds) > 2 else None

    Country_Names.append(countryName)
    Quality_Indexes.append(qualities)

df3 = pd.DataFrame({
    "Country": Country_Names,
    "Quality Of Life Index": Quality_Indexes,
})

print(df3)

response = requests.get(url_for_health)
soup = BeautifulSoup(response.content, "html.parser")

Country_Names=[]
table=soup.tbody
rows = table.find_all("tr")

for row in rows:
    tds = row.find_all("td")
    # extract the values
    countryName=tds[1].text.strip() if len(tds)>1 else None
    healthcareIndex = tds[2].text.strip() if len(tds) > 2 else None

    Country_Names.append(countryName)
    Healthcare_Indexes.append(healthcareIndex)

df4 = pd.DataFrame({
    "Country": Country_Names,
    "HealthCare Index": Healthcare_Indexes,
})

print(df4)

response = requests.get(url_for_cost_of_living)
soup = BeautifulSoup(response.content, "html.parser")

Country_Names=[]
table=soup.tbody
rows = table.find_all("tr")

for row in rows:
    tds = row.find_all("td")
    # extract the values
    countryName=tds[1].text.strip() if len(tds)>1 else None
    costOfliving = tds[2].text.strip() if len(tds) > 2 else None
    rentIndex=tds[3].text.strip() if len(tds)>3 else None
    groceriesIndex=tds[5].text.strip() if len(tds)>3 else None

    Country_Names.append(countryName)
    Costs_Of_Living.append(costOfliving)
    Rents_Indexes.append(rentIndex)
    Groceries_Indexes.append(groceriesIndex)

df5 = pd.DataFrame({
    "Country": Country_Names,
    "Cost Of Living Index": Costs_Of_Living,
    "Rent Index":Rents_Indexes,
    "Groceries Index":Groceries_Indexes
})

print(df5)

response = requests.get(url_for_climate)
soup = BeautifulSoup(response.content, "html.parser")

Country_Names=[]
Climate_Indexes=[]
table=soup.table
rows = table.find_all("tr")

for row in rows[1:]:
    tds = row.find_all("td")
    country=row.find("a")
    # extract the values
    countryName=country.text.strip()
    if tds[3]:
        temperature=tds[3].text.strip()
    else:
       temperature=None
    Climate_Indexes.append(temperature)
    Country_Names.append(countryName)

df6 = pd.DataFrame({
    "Country": Country_Names,
    "Temperature": Climate_Indexes,
})

print(df6)

merged_df = df1.merge(df2, on='Country', how='outer') \
               .merge(df3, on='Country', how='outer') \
               .merge(df4, on='Country', how='outer') \
               .merge(df5, on='Country', how='outer') \
               .merge(df6, on='Country', how='outer')

print(merged_df.head(10))

"""## Data Preprocessing"""

import pandas as pd
import numpy as np
df=merged_df

#Strip column names and remove leading/trailing whitespaces
df.columns = df.columns.str.strip()

#Clean string entries inside the DataFrame (whitespace)
df = df.applymap(lambda x: x.strip() if isinstance(x, str) else x)

#Convert all numeric columns to floats (ignoring 'Country')
for col in df.columns:
    if col != 'Country':
        df[col] = pd.to_numeric(df[col], errors='coerce')

#Drop exact duplicate rows if any
df.drop_duplicates(inplace=True)

# Reset index
df.reset_index(drop=True, inplace=True)

# Drop rows where ALL indices except 'Country' are NaN
df = df.dropna(subset=df.columns.difference(['Country']), how='all')

# Impute missing values with column mean
df.fillna(df.mean(numeric_only=True), inplace=True)

print(df.shape)
print(df.describe())

display(df)

from sklearn.preprocessing import StandardScaler

# Drop 'CountryName' (not numerical)
features = df.drop(columns=['Country'])

# Initialize the scaler
scaler = StandardScaler()

# Fit and transform the features
scaled_features = scaler.fit_transform(features)

# Create a new DataFrame with scaled values and same column names
scaled_df = pd.DataFrame(scaled_features, columns=features.columns)

# Optional: add CountryName back
scaled_df['Country'] = df['Country'].values

# Display the result
print(scaled_df.head())

"""## Data Analysis

### Bar Plot of Correlations with Quality of Life

A horizontal bar chart
showinghow strongly each feature correlates specifically with the Quality of Life
Index.
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Define the features to analyze
feature_cols = [
    'Crime Index', 'Safety Index', 'Pollution Index', 'HealthCare Index',
    'Cost Of Living Index', 'Rent Index', 'Groceries Index', 'Temperature'
]

# Clean string values (if any)
df = df.applymap(lambda x: x.strip() if isinstance(x, str) else x)

# Convert relevant columns to numeric, handle non-numeric values
columns_to_fix = feature_cols + ['Quality Of Life Index']
for col in columns_to_fix:
    df[col] = pd.to_numeric(df[col], errors='coerce')

# Drop rows with NaNs in these columns
df.dropna(subset=columns_to_fix, inplace=True)

# Set up the plot
fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(22, 22))
axes = axes.flatten()

# Create scatter plots with regression lines
for i, col in enumerate(feature_cols):
    sns.regplot(x=df[col], y=df['Quality Of Life Index'], ax=axes[i], scatter_kws={'alpha': 0.6})
    axes[i].set_title(f"{col} vs Quality Of Life Index", fontsize=14)
    axes[i].set_xlabel(col)
    axes[i].set_ylabel('Quality Of Life Index')

# Hide any unused subplot axes (in case there are fewer than 9)
for j in range(len(feature_cols), len(axes)):
    axes[j].axis('off')

plt.tight_layout()
plt.show()

"""### Corelation Heatmap of All Features"""

plt.figure(figsize=(12, 8))
sns.heatmap(df.corr(numeric_only=True), annot=True, cmap='coolwarm', fmt=".2f")
plt.title("Correlation Heatmap of All Features")
plt.show()

"""### Bar Plot of Correlations with Quality of Life:

A horizontal bar chart showing
how strongly each feature correlates specifically with the Quality of Life Index.

"""

correlations = df.corr(numeric_only=True)['Quality Of Life Index'].sort_values()
correlations.plot(kind='barh', figsize=(10, 7), color='skyblue')
plt.title('Feature Correlations with Quality of Life Index')
plt.xlabel('Correlation Coefficient')
plt.grid(True)
plt.show()

"""### Country Rankings Bar Plot

Bar chart of the top 10 countries with the highest
Quality of Life Index.

"""

top_countries = df.sort_values('Quality Of Life Index', ascending=False).head(10)
plt.figure(figsize=(10, 6))
sns.barplot(data=top_countries, x='Quality Of Life Index', y='Country', palette='viridis')
plt.title('Top 10 Countries by Quality of Life Index')
plt.xlabel('Quality of Life Index')
plt.ylabel('Country')
plt.show()

"""## Model Selection and Training

We are training machine learning models to predict the Quality of Life Index (QoLI)
based on the preprocessed dataset.

"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.neighbors import KNeighborsRegressor
from sklearn.metrics import mean_absolute_error
import matplotlib.pyplot as plt
import seaborn as sns

df_model = df.copy()

# Drop Country column for model training
df_model = df_model.drop(columns=['Country'])

# Define features and target
X = df_model.drop(columns=['Quality Of Life Index'])
y = df_model['Quality Of Life Index']

# 2. Train/Test Split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 3. Train multiple models
models = {
    "Linear Regression": LinearRegression(),
    "Random Forest": RandomForestRegressor(random_state=42),
    "Gradient Boosting": GradientBoostingRegressor(random_state=42),
    "K-Nearest Neighbors": KNeighborsRegressor()
}

results = {}
for name, model in models.items():
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    mae = mean_absolute_error(y_test, y_pred)
    results[name] = {"model": model, "mae": mae}
    print(f"{name} - MAE: {mae:.4f}")

# 4. Find the best model
best_model_name = min(results, key=lambda k: results[k]["mae"])
best_model = results[best_model_name]["model"]
print(f"\nâœ… Best Model: {best_model_name} (MAE: {results[best_model_name]['mae']:.4f})")

# Optional: Plot predicted vs actual values for best model
y_best_pred = best_model.predict(X_test)

plt.figure(figsize=(8, 6))
sns.scatterplot(x=y_test, y=y_best_pred)
plt.xlabel("Actual Quality of Life Index")
plt.ylabel("Predicted Quality of Life Index")
plt.title(f"{best_model_name} - Actual vs Predicted")
plt.plot([y.min(), y.max()], [y.min(), y.max()], '--r')
plt.show()

"""## User-Interactive Country Recommendation System

An interactive user interface to predict the Quality of Life Index based on user preferences and recommend the top 5 most similar countries using a trained machine learning model.
"""

import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.metrics.pairwise import euclidean_distances
import ipywidgets as widgets
from IPython.display import display, clear_output

# Createing a widget for each feature in X
feature_widgets = {}

for col in X.columns:
    min_val = float(X[col].min())
    max_val = float(X[col].max())
    mean_val = float(X[col].mean())

    # FloatSlider with a tooltip showing min/max
    slider = widgets.FloatSlider(
        value=mean_val,
        min=min_val,
        max=max_val,
        step=(max_val - min_val) / 100,
        description=col,
        continuous_update=False,
        readout_format='.2f',
        layout=widgets.Layout(width='50%')
    )
    feature_widgets[col] = slider

# Step 2: Create a predict button and output box
predict_button = widgets.Button(description="Predict", button_style='success')
output = widgets.Output()

# Step 3: Prediction function
def on_predict_clicked(b):
    output.clear_output()
    with output:
        # Collect user input into DataFrame
        user_input_dict = {col: widget.value for col, widget in feature_widgets.items()}
        user_input_df = pd.DataFrame([user_input_dict])

        # Scale data
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X)
        user_scaled = scaler.transform(user_input_df)

        # Predict
        user_scaled_df = pd.DataFrame(user_scaled, columns=X.columns)
        predicted_quality = best_model.predict(user_scaled_df)[0]
        print(f"\n Predicted Quality of Life Index for your preferences: {predicted_quality:.4f}")

        # Find top 5 closest countries
        distances = euclidean_distances(X_scaled, user_scaled)
        X_scaled_df = pd.DataFrame(X_scaled, columns=X.columns)
        df_results = pd.DataFrame({
            "Country": df["Country"],
            "Predicted Quality": best_model.predict(X_scaled_df),
            "Distance to You": distances.flatten()
        })

        top_5 = df_results.sort_values(by="Distance to You").head(5)
        print("\n Top 5 countries most similar to your preferences:\n")
        display(top_5[['Country', 'Predicted Quality', 'Distance to You']])

predict_button.on_click(on_predict_clicked)

# Step 4: Display UI
display(widgets.VBox(list(feature_widgets.values()) + [predict_button, output]))